"""
Module pour gÃ©nÃ©rer et ajouter des embeddings Gemini aux documents MeiliSearch.
Ce script peut Ãªtre exÃ©cutÃ© de maniÃ¨re autonome pour traiter les documents existants.
VERSION PROGRESSIVE OPTIMISÃ‰E - Indexation immÃ©diate pour libÃ©rer la mÃ©moire.
"""

import os
import sys
import logging
import time
from typing import List
from pathlib import Path
from meilisearch_python_sdk import Client
from google import genai
from dotenv import load_dotenv
from tqdm import tqdm

# --- Configuration ---
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

# Configurer un logger dÃ©diÃ©
gemini_logger = logging.getLogger("gemini_embedder")
gemini_logger.setLevel(logging.INFO)
if not gemini_logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    gemini_logger.addHandler(handler)


class QuotaExceededError(Exception):
    """Exception levÃ©e lorsque le quota de l'API Gemini est dÃ©passÃ©."""
    pass


class MeiliSearchGemini:
    """GÃ¨re l'indexation avec embeddings Gemini dans MeiliSearch."""

    def __init__(self, meili_url: str, meili_key: str, gemini_api_key: str):
        self.client = meilisearch.Client(meili_url, meili_key)
        self.embedding_model = "text-embedding-004"

        try:
            self.gemini_client = genai.Client(api_key=gemini_api_key)
            gemini_logger.info("âœ“ Gemini API client initialisÃ©.")
        except Exception as e:
            gemini_logger.error(f"âŒ Erreur lors de l'initialisation du client Gemini: {e}")
            self.gemini_client = None

        gemini_logger.info(f"âœ“ MeiliSearch connectÃ© Ã  {meili_url}")
        gemini_logger.info(f"âœ“ ModÃ¨le d'embedding: {self.embedding_model}")

    def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """GÃ©nÃ¨re des embeddings pour un lot de textes."""
        if not self.gemini_client:
            gemini_logger.error("Client Gemini non initialisÃ©. Impossible de gÃ©nÃ©rer les embeddings.")
            return [[] for _ in texts]

        try:
            result = self.gemini_client.models.embed_content(
                model=self.embedding_model,
                contents=texts
            )
            return [embedding.values for embedding in result.embeddings]
        except Exception as e:
            error_str = str(e).lower()
            if "quota" in error_str or "resource exhausted" in error_str:
                gemini_logger.error(f"ğŸ›‘ Quota Gemini dÃ©passÃ©: {e}")
                raise QuotaExceededError(str(e))
            gemini_logger.error(f"âŒ Erreur API Gemini: {e}")
            return [[] for _ in texts]

    def check_embedder_config(self, index_name: str) -> bool:
        """VÃ©rifie que les embedders sont bien configurÃ©s."""
        try:
            index = self.client.index(index_name)
            settings = index.get_settings()
            embedders = settings.get('embedders', {})

            has_default = 'default' in embedders
            has_query = 'query' in embedders

            if has_default and has_query:
                gemini_logger.info("âœ“ Embedders 'default' et 'query' dÃ©jÃ  configurÃ©s")
                return True
            else:
                missing = []
                if not has_default:
                    missing.append('default')
                if not has_query:
                    missing.append('query')
                gemini_logger.warning(f"âš ï¸  Embedders manquants: {', '.join(missing)}")
                gemini_logger.warning("   ExÃ©cutez d'abord: python configure_and_check_meilisearch.py")
                return False
        except Exception as e:
            gemini_logger.error(f"âŒ Erreur lors de la vÃ©rification: {e}")
            return False

    def process_missing_embeddings(self, index_name: str,
                                   batch_size: int = 50,
                                   gemini_batch_size: int = 100):
        """
        Trouve les documents sans embeddings, les gÃ©nÃ¨re et met Ã  jour l'index.
        VERSION PROGRESSIVE: indexe immÃ©diatement aprÃ¨s gÃ©nÃ©ration des embeddings.

        Args:
            index_name: Nom de l'index MeiliSearch
            batch_size: Nombre de documents Ã  rÃ©cupÃ©rer de MeiliSearch par requÃªte
            gemini_batch_size: Nombre d'embeddings Ã  gÃ©nÃ©rer par requÃªte Gemini
        """
        # VÃ©rifier d'abord que les embedders sont configurÃ©s
        if not self.check_embedder_config(index_name):
            print("\nâŒ Configuration incomplÃ¨te. ArrÃªt du processus.")
            return

        index = self.client.index(index_name)
        print("\nğŸ” Recherche des documents sans embeddings...")

        try:
            search_res = index.search('', {'filter': '_vectors.default NOT EXISTS', 'limit': 0})
            total_missing = search_res.get('estimatedTotalHits', 0)
        except Exception as e:
            print(f"âŒ ERREUR: Impossible de compter les documents: {e}")
            return

        if total_missing == 0:
            print("ğŸ‰ Tous les documents ont dÃ©jÃ  des embeddings. Aucune action requise.")
            return

        print(f"ğŸ“Š TrouvÃ©: {total_missing} documents sans embeddings")
        print(f"âš™ï¸  Batch MeiliSearch: {batch_size} documents")
        print(f"âš™ï¸  Batch Gemini: {gemini_batch_size} embeddings")
        print(f"ğŸ”„ Estimation: ~{(total_missing // gemini_batch_size) + 1} requÃªtes API Gemini")
        print(f"ğŸ“¦ Mode: Indexation progressive (mÃ©moire optimisÃ©e)\n")

        with tqdm(total=total_missing, desc="ğŸ“ GÃ©nÃ©ration", unit="doc", file=sys.stdout) as pbar:
            processed_docs_count = 0
            successful_updates = 0
            quota_exceeded = False

            while processed_docs_count < total_missing and not quota_exceeded:
                try:
                    # RÃ©cupÃ©rer un batch de documents sans embeddings
                    docs_to_process = index.get_documents({
                        'filter': '_vectors.default NOT EXISTS',
                        'limit': batch_size,
                        'fields': ['id', 'title', 'content']
                    }).results
                except Exception as e:
                    print(f"\nâŒ ERREUR: RÃ©cupÃ©ration des documents: {e}")
                    time.sleep(5)
                    continue

                if not docs_to_process:
                    break  # TerminÃ©

                # PrÃ©parer les textes pour l'embedding (buffer temporaire)
                texts_buffer = []
                doc_ids_buffer = []

                for doc in docs_to_process:
                    title = getattr(doc, 'title', '')
                    content = getattr(doc, 'content', '')
                    text = f"{title}\n{content}".strip()

                    if text:  # Ne traiter que les docs avec du contenu
                        texts_buffer.append(text)
                        doc_ids_buffer.append(doc.id)

                if not texts_buffer:
                    processed_docs_count += len(docs_to_process)
                    pbar.update(len(docs_to_process))
                    continue

                # INDEXATION PROGRESSIVE: traiter les textes par sous-batches Gemini
                # et indexer immÃ©diatement aprÃ¨s chaque gÃ©nÃ©ration
                for i in range(0, len(texts_buffer), gemini_batch_size):
                    sub_texts = texts_buffer[i:i + gemini_batch_size]
                    sub_doc_ids = doc_ids_buffer[i:i + gemini_batch_size]

                    # GÃ©nÃ©rer les embeddings pour ce sous-batch
                    try:
                        embeddings = self.get_embeddings_batch(sub_texts)
                    except QuotaExceededError:
                        print("\nğŸ›‘ Quota Gemini dÃ©passÃ©. ArrÃªt du processus.")
                        quota_exceeded = True
                        break

                    # PrÃ©parer et indexer IMMÃ‰DIATEMENT (ne pas stocker en mÃ©moire)
                    docs_to_update = []
                    for doc_id, embedding in zip(sub_doc_ids, embeddings):
                        if embedding and len(embedding) == 768:
                            docs_to_update.append({
                                'id': doc_id,
                                '_vectors': {'default': embedding}
                            })

                    # Indexer ce sous-batch immÃ©diatement
                    if docs_to_update:
                        try:
                            task = index.update_documents(docs_to_update)
                            # Attendre que la tÃ¢che se termine
                            self.client.wait_for_task(task.task_uid, timeout_in_ms=30000)
                            successful_updates += len(docs_to_update)

                            # LibÃ©rer la mÃ©moire explicitement
                            del docs_to_update
                            del embeddings

                        except Exception as e:
                            print(f"\nâŒ ERREUR: Mise Ã  jour MeiliSearch: {e}")

                    # Petit dÃ©lai pour Ã©viter de saturer l'API
                    time.sleep(0.3)

                # LibÃ©rer les buffers aprÃ¨s traitement complet du batch
                del texts_buffer
                del doc_ids_buffer

                processed_docs_count += len(docs_to_process)
                pbar.update(len(docs_to_process))

                # Petit dÃ©lai entre les batches MeiliSearch
                time.sleep(0.5)

        # RÃ©sumÃ©
        print("\n" + "="*60)
        if quota_exceeded:
            print(f"âš ï¸  Processus interrompu (quota dÃ©passÃ©)")
        else:
            print(f"âœ… Processus terminÃ©")
        print(f"ğŸ“Š Documents traitÃ©s: {processed_docs_count}")
        print(f"âœ“  Embeddings ajoutÃ©s: {successful_updates}")
        if processed_docs_count > successful_updates:
            print(f"âš ï¸  Ã‰checs: {processed_docs_count - successful_updates}")
        print("="*60)

    def count_documents_stats(self, index_name: str):
        """Affiche des statistiques sur les documents avec/sans embeddings."""
        try:
            index = self.client.index(index_name)

            # Total de documents
            stats = index.get_stats()
            total_docs = stats.get('numberOfDocuments', 0)

            # Documents sans embeddings
            try:
                search_res = index.search('', {'filter': '_vectors.default NOT EXISTS', 'limit': 0})
                docs_without = search_res.get('estimatedTotalHits', 0)
            except:
                docs_without = "N/A"

            # Documents avec embeddings
            docs_with = total_docs - docs_without if isinstance(docs_without, int) else "N/A"

            print("\n" + "="*60)
            print("ğŸ“Š STATISTIQUES DES EMBEDDINGS")
            print("="*60)
            print(f"ğŸ“„ Total de documents: {total_docs}")
            print(f"âœ… Avec embeddings: {docs_with}")
            print(f"âŒ Sans embeddings: {docs_without}")
            if isinstance(docs_with, int) and total_docs > 0:
                percentage = (docs_with / total_docs) * 100
                print(f"ğŸ“ˆ Taux de couverture: {percentage:.1f}%")
            print("="*60 + "\n")

        except Exception as e:
            print(f"âŒ Erreur lors du calcul des statistiques: {e}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Ajouter des embeddings Gemini aux documents MeiliSearch')
    parser.add_argument('--stats', action='store_true', help='Afficher uniquement les statistiques')
    parser.add_argument('--batch-size', type=int, default=50,
                       help='Nombre de documents Ã  rÃ©cupÃ©rer par batch (dÃ©faut: 50)')
    parser.add_argument('--gemini-batch-size', type=int, default=100,
                       help='Nombre d\'embeddings Ã  gÃ©nÃ©rer par requÃªte Gemini (dÃ©faut: 100)')
    args = parser.parse_args()

    MEILI_URL = os.getenv("MEILI_URL")
    MEILI_KEY = os.getenv("MEILI_KEY")
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    INDEX_NAME = os.getenv("INDEX_NAME", "kidsearch")

    if not all([MEILI_URL, MEILI_KEY, GEMINI_API_KEY]):
        print("âŒ ERREUR: MEILI_URL, MEILI_KEY, et GEMINI_API_KEY doivent Ãªtre dÃ©finis dans .env")
        sys.exit(1)

    try:
        meili_gemini = MeiliSearchGemini(
            meili_url=MEILI_URL,
            meili_key=MEILI_KEY,
            gemini_api_key=GEMINI_API_KEY
        )

        if args.stats:
            # Afficher uniquement les statistiques
            meili_gemini.count_documents_stats(INDEX_NAME)
        else:
            # Traiter les documents manquants
            meili_gemini.process_missing_embeddings(
                INDEX_NAME,
                batch_size=args.batch_size,
                gemini_batch_size=args.gemini_batch_size
            )

    except KeyboardInterrupt:
        print("\n\nâš ï¸  Interruption utilisateur (Ctrl+C)")
        print("ğŸ’¡ Vous pouvez relancer le script pour continuer oÃ¹ il s'est arrÃªtÃ©")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Une erreur inattendue est survenue: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)